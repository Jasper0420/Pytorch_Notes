{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本章中，我们将：\n",
    "- 定义一个类来处理模型训练。\n",
    "- 实现构造方法。\n",
    "- 了解类的公共、受保护和私有方法之间的区别。\n",
    "\n",
    "# Imports\n",
    "整个代码中需要的和任何给定章节中使用的所有库都在一开始就导入了。对于本章，我们需要以下导入："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going Classy\n",
    "## 为模型训练构建类 \n",
    "到目前为止， %%writefile 方法帮助我们将代码组织成三个不同的部分：数据准备、模型配置和模型训练。不过，在本章末尾，重新思考训练循环，我们遇到了它的一些局限性，例如，如果不编辑模型训练代码，就无法选择不同数量的 epoch。\n",
    "## The class\n",
    "让我们开始使用一个相当原始的名称来定义我们的类： StepByStep 。因为我们是从头开始的，所以我们要么不指定父类，要么从基本的 object 类继承它。我更喜欢后者，所以我们的类定义如下所示：\n",
    "```python\n",
    "# A completely empty (and useless) class\n",
    "class StepByStep(object):\n",
    "\tpass\n",
    "```\n",
    "## 构造函数\n",
    "“我们从哪里开始建立一个类？”那将是构造函数； __init__(self) 方法，我们在处理模型和数据集类时已经见过几次。\n",
    "\n",
    "构造函数定义组成类的部分。这些部分是类的属性。典型的属性包括：\n",
    "-  用户提供的参数。\n",
    "-  创建时不可用的其他对象的占位符（非常类似于延迟参数）。\n",
    "-  我们可能想要跟踪的变量。\n",
    "-  使用一些参数和高阶函数动态构建的函数。\n",
    "\n",
    "## Arguments 参数 \n",
    "让我们从参数开始，这是需要由用户指定的部分。在“重新思考训练循环”这一章的开头，我们问自己：“如果我们使用不同的优化器、损失函数甚至模型，训练循环中的代码会发生变化吗？”答案过去是，现在仍然是，不会改变。因此，**优化器、损失和模型**这三个要素将是我们的主要论点。用户需要指定这些；我们无法自己计算出来。\n",
    "\n",
    "但是还需要一条信息；用于训练模型的设备。我们不会要求用户通知它，而是会自动检查是否有可用的 GPU，如果没有则回退到 CPU。但是我们仍然希望给用户一个使用不同设备的机会，因此，我们添加了一个非常简单的方法，名为 to ，允许用户指定一个设备。添加所有参数后，我们的构造函数 ( __init__ ) 方法最初将如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepByStep(object):\n",
    "    #三大参数：模型，损失函数，优化器\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        # Here we define the attributes of our class\n",
    "        # We start by storing the arguments as attributes \n",
    "        # to use them later\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # Let's send the model to the specified device right away\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "    def to(self, device):\n",
    "        # This method allows the user to specify a different device\n",
    "        # It sets the corresponding attribute (to be used later in\n",
    "        # the mini-batches) and sends the model to the device\n",
    "        self.device = device\n",
    "        self.model.to(self.device)        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholders 占位符 \n",
    "接下来，让我们处理占位符或延迟参数。我们希望用户最终提供其中一些，因为它们不一定是必需的。在我们的课程中，还有另外三个元素属于此类：训练和验证数据加载器以及与 TensorBoard 交互的摘要编写器。带有附加代码的构造函数如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepByStep(object):\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        # Here we define the attributes of our class\n",
    "        \n",
    "        # We start by storing the arguments as attributes \n",
    "        # to use them later\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # Let's send the model to the specified device right away\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        # These attributes are defined here, but since they are\n",
    "        # not available at the moment of creation, we keep them None\n",
    "        self.train_loader = None\n",
    "        self.val_loader = None\n",
    "        self.writer = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "换句话说，我们的 StepByStep 类由参数、模型、损失函数和优化器的特定组合定义，然后可用于在任何兼容数据集上执行模型训练。验证数据加载器不是必需的（尽管建议使用），摘要编写器绝对是可选的。因此，该类应该实现允许用户稍后通知这些方法的方法。这两个方法都应该放在 StepByStep 类中和构造方法之后："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_loaders(self, train_loader, val_loader=None):\n",
    "    # This method allows the user to define which train_loader \n",
    "    # (and val_loader, optionally) to use\n",
    "    # Both loaders are then assigned to attributes of the class\n",
    "    # So they can be referred to later\n",
    "    self.train_loader = train_loader\n",
    "    self.val_loader = val_loader\n",
    "\n",
    "def set_tensorboard(self, name, folder='runs'):\n",
    "    # This method allows the user to create a SummaryWriter to \n",
    "    # interface with TensorBoard\n",
    "    suffix = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "    self.writer = SummaryWriter('{}/{}_{}'.format(\n",
    "        folder, name, suffix\n",
    "    ))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“为什么我们需要为 val_loader 指定一个默认值？它的占位符值已经是 None 。”由于验证加载器是可选的，因此在方法定义中为特定参数设置默认值可以使用户在调用方法时不必提供该参数。在我们的例子中，最佳默认值与我们在为验证加载器指定占位符时选择的值相同： None 。\n",
    "## Variables 变量 \n",
    "然后，我们可能想要跟踪一些变量。典型的例子是 epoch 的数量以及训练和验证损失。这些变量很可能由类在内部计算和更新。带有附加代码的构造函数将如下所示，类似于我们对占位符所做的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepByStep(object):\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        # Here we define the attributes of our class\n",
    "        \n",
    "        # We start by storing the arguments as attributes \n",
    "        # to use them later\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # Let's send the model to the specified device right away\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        # These attributes are defined here, but since they are\n",
    "        # not available at the moment of creation, we keep them None\n",
    "        self.train_loader = None\n",
    "        self.val_loader = None\n",
    "        self.writer = None\n",
    "\n",
    "        # These attributes are going to be computed internally\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.total_epochs = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“难道我们不能在第一次使用它们时就设置这些变量吗？”\n",
    "\n",
    "是的，我们可以，而且我们可能会侥幸逃脱，因为我们的课程非常简单。随着类变得越来越复杂，它可能会导致问题。因此，最好的做法是在构造方法中定义一个类的所有属性。\n",
    "\n",
    "更新后的 StepByStep 类现在如下所示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepByStep(object):\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        # Here we define the attributes of our class\n",
    "        \n",
    "        # We start by storing the arguments as attributes \n",
    "        # to use them later\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # Let's send the model to the specified device right away\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        # These attributes are defined here, but since they are\n",
    "        # not available at the moment of creation, we keep them None\n",
    "        self.train_loader = None\n",
    "        self.val_loader = None\n",
    "        self.writer = None\n",
    "        \n",
    "        # These attributes are going to be computed internally\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.total_epochs = 0\n",
    "\n",
    "    def to(self, device):\n",
    "        # This method allows the user to specify a different device\n",
    "        # It sets the corresponding attribute (to be used later in\n",
    "        # the mini-batches) and sends the model to the device\n",
    "        self.device = device\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def set_loaders(self, train_loader, val_loader=None):\n",
    "        # This method allows the user to define which train_loader \n",
    "        # (and val_loader, optionally) to use\n",
    "        # Both loaders are then assigned to attributes of the class\n",
    "        # So they can be referred to later\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "\n",
    "    def set_tensorboard(self, name, folder='runs'):\n",
    "        # This method allows the user to create a SummaryWriter to \n",
    "        # interface with TensorBoard\n",
    "        suffix = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        self.writer = SummaryWriter('{}/{}_{}'.format(\n",
    "            folder, name, suffix\n",
    "        ))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions 函数\n",
    "## 创建函数属性\n",
    "为方便起见，有时创建作为函数的属性很有用，这些属性将在类内的其他地方调用。在我们的例子中，我们可以使用我们在重新思考训练循环一章中定义的高阶函数（分别是辅助函数#1 和#3）来创建 train_step 和 val_step 。它们都以一个模型、一个损失函数和一个优化器作为参数，所有这些都是我们 StepByStep 类在构造时已知的属性。下面的代码将是我们构造函数方法的最终更新版本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepByStep(object):\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        # Here we define the attributes of our class\n",
    "        \n",
    "        # We start by storing the arguments as attributes \n",
    "        # to use them later\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # Let's send the model to the specified device right away\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        # These attributes are defined here, but since they are\n",
    "        # not available at the moment of creation, we keep them None\n",
    "        self.train_loader = None\n",
    "        self.val_loader = None\n",
    "        self.writer = None\n",
    "\n",
    "        # These attributes are going to be computed internally\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.total_epochs = 0\n",
    "\n",
    "        # Creates the train_step function for our model, \n",
    "        # loss function and optimizer\n",
    "        # Note: there are NO ARGS there! It makes use of the class\n",
    "        # attributes directly\n",
    "        self.train_step = self._make_train_step()\n",
    "        # Creates the val_step function for our model and loss\n",
    "        self.val_step = self._make_val_step()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将所有代码拼凑在一起后，您的 StepByStep 类应该如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepByStep(object):\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        # Here we define the attributes of our class\n",
    "        # We start by storing the arguments as attributes \n",
    "        # to use them later\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # Let's send the model to the specified device right away\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        # These attributes are defined here, but since they are\n",
    "        # not available at the moment of creation, we keep them None\n",
    "        self.train_loader = None\n",
    "        self.val_loader = None\n",
    "        self.writer = None\n",
    "\n",
    "        # These attributes are going to be computed internally\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.total_epochs = 0\n",
    "\n",
    "        # Creates the train_step function for our model, \n",
    "        # loss function and optimizer\n",
    "        # Note: there are NO ARGS there! It makes use of the class\n",
    "        # attributes directly\n",
    "        self.train_step = self._make_train_step()\n",
    "        # Creates the val_step function for our model and loss\n",
    "        self.val_step = self._make_val_step()\n",
    "\n",
    "    def to(self, device):\n",
    "        # This method allows the user to specify a different device\n",
    "        # It sets the corresponding attribute (to be used later in\n",
    "        # the mini-batches) and sends the model to the device\n",
    "        self.device = device\n",
    "        self.model.to(self.device)        \n",
    "        \n",
    "    def set_loaders(self, train_loader, val_loader=None):\n",
    "        # This method allows the user to define which train_loader \n",
    "        # (and val_loader, optionally) to use\n",
    "        # Both loaders are then assigned to attributes of the class\n",
    "        # So they can be referred to later\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "\n",
    "    def set_tensorboard(self, name, folder='runs'):\n",
    "        # This method allows the user to create a SummaryWriter to \n",
    "        # interface with TensorBoard\n",
    "        suffix = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        self.writer = SummaryWriter('{}/{}_{}'.format(\n",
    "            folder, name, suffix\n",
    "        ))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不同的方法类型\n",
    "在上节中，我们介绍了 _make_train_step 和 _make_val_step 方法，并注意到这些方法有一个下划线作为前缀。为什么会这样，这与 __init__ 方法中的双下划线有何不同？”\n",
    "## 公共、受保护和私有方法 \n",
    "某些编程语言（如 Java）具有三种方法：公共、受保护和私有.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "公共方法是您最熟悉的一种；他们可以被用户调用。另一方面，受保护的方法不应由用户调用。它们应该在内部或由子类调用（子类可以从其父类调用受保护的方法）。\n",
    "\n",
    "最后，私有方法应该只在内部调用。他们甚至应该对子类不可见。\n",
    "\n",
    "这些规则在 Java 中严格执行，但 Python 采取更宽松的方法；所有方法都是公开的。意思是，你可以调用任何你想要的方法。但是您可以通过在方法名称前加上**单个下划线（对于受保护的方法）**或**双下划线（对于私有方法）**作为前缀来建议适当的用法。这样，用户就知道程序员的意图了。\n",
    "\n",
    "在我们的示例中， _make_train_step 和 _make_val_step 都被定义为受保护的方法。我们希望用户不要直接调用它们，但如果有人决定定义一个继承自 StepByStep 的类，他们应该觉得有权这样做。\n",
    "\n",
    "为了使我们的代码的添加看起来更简单，也就是说，不必在每次引入新方法时都复制完整的类，我求助于在常规情况下不应使用的东西： setattr 。这个函数允许我们在运行时动态地添加属性。我们可以使用它来添加我们的 _make_train_step 和 _make_val_step 方法。我们还可以使用它来添加我们的 train_step 和 val_step 方法。这些方法将在我们的训练循环中使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_make_train_step' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_18360/2727802079.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# ATTENTION! Using SETATTR for educational purposes only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStepByStep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_make_train_step'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_make_train_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStepByStep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_make_val_step'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_make_val_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '_make_train_step' is not defined"
     ]
    }
   ],
   "source": [
    "# ATTENTION! Using SETATTR for educational purposes only \n",
    "setattr(StepByStep, '_make_train_step', _make_train_step)\n",
    "setattr(StepByStep, '_make_val_step', _make_val_step)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setattr 是什么？\n",
    "setattr 函数设置给定对象的指定属性的值。但是方法也是属性，所以我们可以使用这个函数一次性将方法“附加”到现有类及其所有现有实例！你不应该在你的常规代码中使用它！使用 setattr 通过向其附加方法来构建类仅用于教育目的。\n",
    "\n",
    "为了说明它是如何工作的以及为什么它可能是危险的，将向您展示一个小例子。让我们创建一个简单的 Dog 类，它只接受狗的名字作为参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dog(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，让我们实例化我们的类；也就是说，我们正在创造一只狗。让我们称它为 Rex 。它的名称将存储在 name 属性中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rex\n"
     ]
    }
   ],
   "source": [
    "class Dog(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "rex = Dog('Rex')\n",
    "print(rex.name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，让我们创建一个以 Dog 实例作为参数的 bark 函数，并调用此函数来发出 Rex 吠声："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rex barks: \"Woof!\"\n"
     ]
    }
   ],
   "source": [
    "def bark(dog):\n",
    "    print('{} barks: \"Woof!\"'.format(dog.name))\n",
    "\n",
    "bark(rex)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但这不是我们想要的。我们希望我们的狗能够开箱即用地吠叫！所以我们将使用 setattr 来赋予狗吠叫的能力。不过有一件事我们需要改变，那就是函数的参数。由于我们希望 bark 函数是 Dog 类本身的一个方法，因此参数需要是该方法自己的实例： self 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bark(self):\n",
    "    print('{} barks: \"Woof!\"'.format(self.name))\n",
    "\n",
    "setattr(Dog, 'bark', bark)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "它有效吗？让我们创建一只新狗："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fido barks: \"Woof!\"\n"
     ]
    }
   ],
   "source": [
    "def bark(self):\n",
    "    print('{} barks: \"Woof!\"'.format(self.name))\n",
    "#第一个参数是类，第二个参数是方法名，第三个参数是方法\n",
    "setattr(Dog, 'Bark', bark)\n",
    "\n",
    "fido = Dog('Fido')\n",
    "fido.Bark()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然，它有效！现在不仅新狗会叫，所有的狗都会叫："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rex barks: \"Woof!\"\n"
     ]
    }
   ],
   "source": [
    "def bark(self):\n",
    "    print('{} barks: \"Woof!\"'.format(self.name))\n",
    "\n",
    "setattr(Dog, 'bark', bark)\n",
    "\n",
    "rex = Dog('Rex')\n",
    "rex.bark()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看？我们一次有效地修改了底层 Dog 类及其所有实例！当然，它看起来很酷。它也会造成严重破坏。使用 setattr 是一种 hack。我们怎么强调都不为过！请不要在常规代码中使用 setattr 。\n",
    "\n",
    "不像我们目前所做的那样直接在类中创建属性或方法，而是可以使用 setattr 动态创建它们。在我们的 StepByStep 类中，最后两行代码在类中创建了两个方法，每个方法都与用于创建该方法的函数同名。\n",
    "\n",
    "# 训练方法\n",
    "## 更新小批量 \n",
    "我们需要的下一个方法是添加对应于“重新思考训练循环”一章中的辅助函数#2：小批量循环。在将它合并到我们的 StepByStep 类之前，我们需要对其进行一些修改。\n",
    "\n",
    "在前面的函数中，数据加载器和步骤函数都是参数。但是，情况不再如此，因为我们将它们都作为属性： **self.train_loader 和 self.train_step 用于训练； self.val_loader 和 self.val_step 用于验证**。该方法唯一需要知道的是它是在处理训练数据还是验证数据。更新后的代码应如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mini_batch(self, validation=False):\n",
    "    # The mini-batch can be used with both loaders\n",
    "    # The argument `validation`defines which loader and \n",
    "    # corresponding step function is going to be used\n",
    "    if validation:\n",
    "        data_loader = self.val_loader\n",
    "        step = self.val_step\n",
    "    else:\n",
    "        data_loader = self.train_loader\n",
    "        step = self.train_step\n",
    "\n",
    "    if data_loader is None:\n",
    "        return None\n",
    "\n",
    "    # Once the data loader and step function are set, this is the\n",
    "    # same mini-batch loop we had before\n",
    "    mini_batch_losses = []\n",
    "    for x_batch, y_batch in data_loader:\n",
    "        x_batch = x_batch.to(self.device)\n",
    "        y_batch = y_batch.to(self.device)\n",
    "        mini_batch_loss = step(x_batch, y_batch)\n",
    "        mini_batch_losses.append(mini_batch_loss)\n",
    "\n",
    "    loss = np.mean(mini_batch_losses)\n",
    "    return loss\n",
    "\n",
    "setattr(StepByStep, '_mini_batch', _mini_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此外，如果用户决定不提供验证加载器，它将保留来自构造方法的初始 None 值。如果是这种情况，我们就没有相应的损失来计算，而是返回 None （上面代码片段中的第 13 行）。\n",
    "## 更新训练循环\n",
    "还剩下什么？当然是训练循环！它将类似于我们在“重新思考训练循环”一章中训练 V5 模型，但我们可以使其更加灵活，将轮数和随机种子作为参数。\n",
    "\n",
    "这解决了我们在“重新思考训练循环”一章中遇到的问题，当时我们不得不在加载一个检查点后再训练 200 个 epoch，因为它被硬编码到训练循环中。好吧，不再是了！\n",
    "\n",
    "此外，我们需要确保训练循环的**可重复性**。我们已经设置了种子以确保随机拆分（数据准备）和模型初始化（模型配置）的可重复性。到目前为止，我们按顺序运行整个管道，因此训练循环每次都产生相同的结果。现在，为了在不影响可重复性的情况下获得灵活性，我们需要设置另一个随机种子。\n",
    "\n",
    "我们正在构建一种仅处理种子设置的方法，遵循 PyTorch 的可重复性指南："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(self, seed=42):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False    \n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "setattr(StepByStep, 'set_seed', set_seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "具体来说，这段代码将 PyTorch 和 NumPy 的随机数种子都设置为 seed，以保证每次运行时都能产生相同的随机数序列。另外，还将 PyTorch 的一些优化库的行为进行了调整，以确保程序的可复现性。\n",
    "\n",
    "具体地，torch.backends.cudnn.deterministic 设置为 True 表示启用 CuDNN 的随机数生成器的可重复模式，从而使每次运行时都能产生相同的随机数序列；torch.backends.cudnn.benchmark 设置为 False 表示禁用 CuDNN 的自动调整算法，以保证程序的可复现性；torch.manual_seed(seed) 将 PyTorch 的随机数种子设置为 seed；np.random.seed(seed) 将 NumPy 的随机数种子设置为 seed。这样，每次运行代码时，都会使用相同的随机数种子，从而产生相同的随机数序列。\n",
    "\n",
    "也是时候使用我们在构造函数方法中定义为属性的变量： self.total_epochs 、 self.losses 和 self.val_losses 。所有这些都在训练循环中更新。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, n_epochs, seed=42):\n",
    "    # To ensure reproducibility of the training process\n",
    "    self.set_seed(seed)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        # Keeps track of the numbers of epochs\n",
    "        # by updating the corresponding attribute\n",
    "        self.total_epochs += 1\n",
    "\n",
    "        # inner loop\n",
    "        # Performs training using mini-batches\n",
    "        loss = self._mini_batch(validation=False)\n",
    "        self.losses.append(loss)\n",
    "\n",
    "        # VALIDATION\n",
    "        # no gradients in validation!\n",
    "        with torch.no_grad():\n",
    "            # Performs evaluation using mini-batches\n",
    "            val_loss = self._mini_batch(validation=True)\n",
    "            self.val_losses.append(val_loss)\n",
    "\n",
    "        # If a SummaryWriter has been set...\n",
    "        if self.writer:\n",
    "            scalars = {'training': loss}\n",
    "            if val_loss is not None:\n",
    "                scalars.update({'validation': val_loss})\n",
    "            # Records both losses for each epoch under tag \"loss\"\n",
    "            self.writer.add_scalars(main_tag='loss',\n",
    "                                    tag_scalar_dict=scalars,\n",
    "                                    global_step=epoch)\n",
    "\n",
    "    if self.writer:\n",
    "        # Flushes the writer\n",
    "        self.writer.flush()\n",
    "        \n",
    "setattr(StepByStep, 'train', train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码定义了 train 方法，用于训练模型。该方法接受两个参数：n_epochs 表示要训练多少个 epoch，seed 表示随机数种子，用于保证训练过程的可重复性。\n",
    "\n",
    "在方法中，首先通过调用 self.set_seed(seed) 方法设置随机数种子，以确保每次训练的结果是可重复的。然后，使用一个 for 循环迭代执行 n_epochs 次训练。\n",
    "\n",
    "在循环的每一次迭代中，首先更新 self.total_epochs 属性的值，表示当前已经训练的 epoch 数。然后调用 _mini_batch 方法进行 mini-batch 训练，并将返回的 loss 值添加到 self.losses 列表中。之后，使用 with torch.no_grad() 块对验证过程进行包装，确保在验证过程中不会计算梯度。在 with 块中，调用 _mini_batch 方法进行 mini-batch 验证，并将返回的验证损失值添加到 self.val_losses 列表中。\n",
    "\n",
    "最后，如果在 StepByStep 对象中设置了 writer 属性，表示要使用 TensorBoard 进行可视化。则通过调用 TensorBoard 的 add_scalars 方法，将训练损失值和验证损失值记录到 TensorBoard 日志中。在训练结束后，如果设置了 writer 属性，则调用 flush 方法将 TensorBoard 日志写入磁盘。\n",
    "\n",
    "这个方法的目的是训练模型，其内部通过迭代训练和验证来更新模型参数，同时记录训练和验证损失值，方便后续分析模型性能。\n",
    "\n",
    "您是否注意到此函数不返回任何内容？它不需要！它不返回值，而只是更新几个类属性： self.losses 、 self.val_losses 和 self.total_epochs 。StepByStep 类的当前开发状态​​已经允许我们完全训练模型。现在，让我们也为我们的班级提供保存和加载模型的能力。\n",
    "## 保存和加载模型\n",
    "这里的大部分代码与我们在重新思考训练循环一章中的代码相同。唯一的区别是我们将使用类属性而不是局部变量。\n",
    "保存检查点的更新方法现在应该如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(self, filename):\n",
    "    # Builds dictionary with all elements for resuming training\n",
    "    checkpoint = {\n",
    "        'epoch': self.total_epochs,\n",
    "        'model_state_dict': self.model.state_dict(),\n",
    "        'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "        'loss': self.losses,\n",
    "        'val_loss': self.val_losses\n",
    "    }\n",
    "\n",
    "    torch.save(checkpoint, filename)\n",
    "    \n",
    "setattr(StepByStep, 'save_checkpoint', save_checkpoint)\n",
    "#这段代码实现了将模型的参数、优化器状态、以及训练损失和验证损失保存到文件的功能。具体来说：\n",
    "# 首先，该方法接受一个参数filename，表示要将训练过程中的所有元素保存到哪个文件中。\n",
    "# 接下来，代码构建了一个字典checkpoint，将以下所有元素都保存在其中：\n",
    "# 当前训练的轮数，即total_epochs属性。\n",
    "# 模型的状态字典，即model.state_dict()。\n",
    "# 优化器的状态字典，即optimizer.state_dict()。\n",
    "# 训练过程中的所有损失，即losses属性。\n",
    "# 验证过程中的所有损失，即val_losses属性。\n",
    "# 最后，调用torch.save函数将checkpoint保存到filename指定的文件中。\n",
    "# 该方法的作用是在训练模型时定期保存模型的参数和损失值，以便在训练过程中出现异常或需要暂停训练时，可以从之前的状态继续训练，节省时间和资源。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此外，加载检查点方法应如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(self, filename):\n",
    "    # Loads dictionary\n",
    "    checkpoint = torch.load(filename)\n",
    "\n",
    "    # Restore state for model and optimizer\n",
    "    self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    self.optimizer.load_state_dict(\n",
    "        checkpoint['optimizer_state_dict']\n",
    "    )\n",
    "\n",
    "    self.total_epochs = checkpoint['epoch']\n",
    "    self.losses = checkpoint['loss']\n",
    "    self.val_losses = checkpoint['val_loss']\n",
    "\n",
    "    self.model.train() # always use TRAIN for resuming training   \n",
    "    \n",
    "setattr(StepByStep, 'load_checkpoint', load_checkpoint)\n",
    "# 这段代码定义了一个名为load_checkpoint()的方法，它接受一个文件名作为参数。\n",
    "# 这个方法的目的是加载之前保存的PyTorch模型和优化器状态的检查点。\n",
    "\n",
    "# 首先，该方法使用torch.load(filename)方法加载保存的检查点文件并将其存储在checkpoint变量中。\n",
    "\n",
    "# 然后，该方法使用load_state_dict()方法将模型的状态从checkpoint字典中的model_state_dict键中恢复，\n",
    "# 并将优化器的状态从checkpoint字典中的optimizer_state_dict键中恢复。这个过程确保了我们加载了之前\n",
    "# 保存的模型和优化器的状态，从而可以继续训练或测试该模型。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 做出预测 \n",
    "做预测呢？为了让用户更容易对任何新数据点进行预测，我们将在此函数内处理所有 Numpy 到 PyTorch 的来回转换："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, x):\n",
    "    # Set it to evaluation mode for predictions\n",
    "    self.model.eval() \n",
    "    # Takes a Numpy input and make it a float tensor\n",
    "    x_tensor = torch.as_tensor(x).float()\n",
    "    # Send input to device and uses model for prediction\n",
    "    y_hat_tensor = self.model(x_tensor.to(self.device))\n",
    "    # Set it back to train mode\n",
    "    self.model.train()\n",
    "    # Detaches it, brings it to CPU and back to Numpy\n",
    "    return y_hat_tensor.detach().cpu().numpy()\n",
    "\n",
    "setattr(StepByStep, 'predict', predict)\n",
    "# 这段代码首先定义了一个名为predict的方法，它接受一个输入x，并使用训练好的模型进行预测。该方法实现的步骤包括：\n",
    "\n",
    "# 将模型设置为评估模式，以便进行预测，即调用self.model.eval()方法。\n",
    "# 将输入x转换为PyTorch张量，并将其发送到模型所在的设备上（例如GPU）进行预测，即调用self.model(x_tensor.to(self.device))方法。\n",
    "# 将模型设置回训练模式，以便进行后续的训练，即调用self.model.train()方法。\n",
    "# 将预测结果从PyTorch张量中分离出来，并将其移动到CPU上，并将其转换回Numpy数组，即调用y_hat_tensor.detach().cpu().numpy()方法。\n",
    "# 然后，使用setattr()函数将predict方法添加到StepByStep类中，以便在该类的实例中可以调用该方法。\n",
    "\n",
    "# 总之，这段代码实现了一个简单的模型预测功能，将输入x作为模型的输入，并返回模型的输出结果。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 完成进入 Classy 所需的方法\n",
    "## 可视化方法 \n",
    "由于我们将训练损失和验证损失都作为属性进行跟踪，因此让我们为它们构建一个简单的绘图函数，如下所示：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(self):\n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    plt.plot(self.losses, label='Training Loss', c='b')\n",
    "    if self.val_loader:\n",
    "        plt.plot(self.val_losses, label='Validation Loss', c='r')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "setattr(StepByStep, 'plot_losses', plot_losses)\n",
    "\n",
    "# 这段代码定义了一个名为plot_losses的方法，用于绘制训练过程中的损失值。该方法实现的步骤包括：\n",
    "\n",
    "# 创建一个大小为(10, 4)的新图形，即调用plt.figure(figsize=(10, 4))方法。\n",
    "# 绘制训练损失曲线，即调用plt.plot(self.losses, label='Training Loss', c='b')方法。\n",
    "# 如果提供了验证数据集，则还绘制验证损失曲线，即调用plt.plot(self.val_losses, label='Validation Loss', c='r')方法。\n",
    "# 将y轴设置为对数刻度，以便更好地显示损失值，即调用plt.yscale('log')方法。\n",
    "# 设置x轴和y轴的标签，即调用plt.xlabel('Epochs')和plt.ylabel('Loss')方法。\n",
    "# 添加图例并自适应布局，即调用plt.legend()和plt.tight_layout()方法。\n",
    "# 返回整个图形，即fig变量。\n",
    "# 然后，使用setattr()函数将plot_losses方法添加到StepByStep类中，以便在该类的实例中可以调用该方法。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，如果训练加载器和 TensorBoard 都已经配置好，我们可以使用前者获取单个 mini-batch，使用后者在 TensorBoard 中构建模型图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_graph(self):\n",
    "    if self.train_loader and self.writer:\n",
    "        # Fetches a single mini-batch so we can use add_graph\n",
    "        x_dummy, y_dummy = next(iter(self.train_loader))\n",
    "        self.writer.add_graph(self.model, x_dummy.to(self.device))\n",
    "    \n",
    "setattr(StepByStep, 'add_graph', add_graph)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样，我们的 StepByStep 类就完成了。结合我们目前讨论的所有代码片段，您可以在下面找到 StepByStep 类的完整代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "class StepByStep(object):\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        # Here we define the attributes of our class\n",
    "        \n",
    "        # We start by storing the arguments as attributes \n",
    "        # to use them later\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # Let's send the model to the specified device right away\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # These attributes are defined here, but since they are\n",
    "        # not informed at the moment of creation, we keep them None\n",
    "        self.train_loader = None\n",
    "        self.val_loader = None\n",
    "        self.writer = None\n",
    "        \n",
    "        # These attributes are going to be computed internally\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.total_epochs = 0\n",
    "\n",
    "        # Creates the train_step function for our model, \n",
    "        # loss function and optimizer\n",
    "        # Note: there are NO ARGS there! It makes use of the class\n",
    "        # attributes directly\n",
    "        self.train_step = self._make_train_step()\n",
    "        # Creates the val_step function for our model and loss\n",
    "        self.val_step = self._make_val_step()\n",
    "\n",
    "    def to(self, device):\n",
    "        # This method allows the user to specify a different device\n",
    "        # It sets the corresponding attribute (to be used later in\n",
    "        # the mini-batches) and sends the model to the device\n",
    "        self.device = device\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def set_loaders(self, train_loader, val_loader=None):\n",
    "        # This method allows the user to define which train_loader (and val_loader, optionally) to use\n",
    "        # Both loaders are then assigned to attributes of the class\n",
    "        # So they can be referred to later\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "\n",
    "    def set_tensorboard(self, name, folder='runs'):\n",
    "        # This method allows the user to define a SummaryWriter to interface with TensorBoard\n",
    "        suffix = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        self.writer = SummaryWriter('{}/{}_{}'.format(\n",
    "            folder, name, suffix\n",
    "        ))\n",
    "\n",
    "    def _make_train_step(self):\n",
    "        # This method does not need ARGS... it can refer to\n",
    "        # the attributes: self.model, self.loss_fn and self.optimizer\n",
    "        \n",
    "        # Builds function that performs a step in the train loop\n",
    "        def perform_train_step(x, y):\n",
    "            # Sets model to TRAIN mode\n",
    "            self.model.train()\n",
    "\n",
    "            # Step 1 - Computes our model's predicted output - forward pass\n",
    "            yhat = self.model(x)\n",
    "            # Step 2 - Computes the loss\n",
    "            loss = self.loss_fn(yhat, y)\n",
    "            # Step 3 - Computes gradients for both \"a\" and \"b\" parameters\n",
    "            loss.backward()\n",
    "            # Step 4 - Updates parameters using gradients and the learning rate\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Returns the loss\n",
    "            return loss.item()\n",
    "\n",
    "        # Returns the function that will be called inside the train loop\n",
    "        return perform_train_step\n",
    "    \n",
    "    def _make_val_step(self):\n",
    "        # Builds function that performs a step in the validation loop\n",
    "        def perform_val_step(x, y):\n",
    "            # Sets model to EVAL mode\n",
    "            self.model.eval()\n",
    "\n",
    "            # Step 1 - Computes our model's predicted output - forward pass\n",
    "            yhat = self.model(x)\n",
    "            # Step 2 - Computes the loss\n",
    "            loss = self.loss_fn(yhat, y)\n",
    "            # There is no need to compute Steps 3 and 4, \n",
    "            # since we don't update parameters during evaluation\n",
    "            return loss.item()\n",
    "\n",
    "        return perform_val_step\n",
    "            \n",
    "    def _mini_batch(self, validation=False):\n",
    "        # The mini-batch can be used with both loaders\n",
    "        # The argument `validation`defines which loader and \n",
    "        # corresponding step function is going to be used\n",
    "        if validation:\n",
    "            data_loader = self.val_loader\n",
    "            step = self.val_step\n",
    "        else:\n",
    "            data_loader = self.train_loader\n",
    "            step = self.train_step\n",
    "\n",
    "        if data_loader is None:\n",
    "            return None\n",
    "            \n",
    "        # Once the data loader and step function, this is the \n",
    "        # same mini-batch loop we had before\n",
    "        mini_batch_losses = []\n",
    "        for x_batch, y_batch in data_loader:\n",
    "            x_batch = x_batch.to(self.device)\n",
    "            y_batch = y_batch.to(self.device)\n",
    "\n",
    "            mini_batch_loss = step(x_batch, y_batch)\n",
    "            mini_batch_losses.append(mini_batch_loss)\n",
    "\n",
    "        loss = np.mean(mini_batch_losses)\n",
    "        return loss\n",
    "\n",
    "    def set_seed(self, seed=42):\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False    \n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    def train(self, n_epochs, seed=42):\n",
    "        # To ensure reproducibility of the training process\n",
    "        self.set_seed(seed)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            # Keeps track of the numbers of epochs\n",
    "            # by updating the corresponding attribute\n",
    "            self.total_epochs += 1\n",
    "\n",
    "            # inner loop\n",
    "            # Performs training using mini-batches\n",
    "            loss = self._mini_batch(validation=False)\n",
    "            self.losses.append(loss)\n",
    "\n",
    "            # VALIDATION\n",
    "            # no gradients in validation!\n",
    "            with torch.no_grad():\n",
    "                # Performs evaluation using mini-batches\n",
    "                val_loss = self._mini_batch(validation=True)\n",
    "                self.val_losses.append(val_loss)\n",
    "\n",
    "            # If a SummaryWriter has been set...\n",
    "            if self.writer:\n",
    "                scalars = {'training': loss}\n",
    "                if val_loss is not None:\n",
    "                    scalars.update({'validation': val_loss})\n",
    "                # Records both losses for each epoch under the main tag \"loss\"\n",
    "                self.writer.add_scalars(main_tag='loss',\n",
    "                                        tag_scalar_dict=scalars,\n",
    "                                        global_step=epoch)\n",
    "\n",
    "        if self.writer:\n",
    "            # Closes the writer\n",
    "            self.writer.close()\n",
    "\n",
    "    def save_checkpoint(self, filename):\n",
    "        # Builds dictionary with all elements for resuming training\n",
    "        checkpoint = {'epoch': self.total_epochs,\n",
    "                      'model_state_dict': self.model.state_dict(),\n",
    "                      'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                      'loss': self.losses,\n",
    "                      'val_loss': self.val_losses}\n",
    "\n",
    "        torch.save(checkpoint, filename)\n",
    "\n",
    "    def load_checkpoint(self, filename):\n",
    "        # Loads dictionary\n",
    "        checkpoint = torch.load(filename)\n",
    "\n",
    "        # Restore state for model and optimizer\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "        self.total_epochs = checkpoint['epoch']\n",
    "        self.losses = checkpoint['loss']\n",
    "        self.val_losses = checkpoint['val_loss']\n",
    "\n",
    "        self.model.train() # always use TRAIN for resuming training   \n",
    "\n",
    "    def predict(self, x):\n",
    "        # Set is to evaluation mode for predictions\n",
    "        self.model.eval() \n",
    "        # Takes aNumpy input and make it a float tensor\n",
    "        x_tensor = torch.as_tensor(x).float()\n",
    "        # Send input to device and uses model for prediction\n",
    "        y_hat_tensor = self.model(x_tensor.to(self.device))\n",
    "        # Set it back to train mode\n",
    "        self.model.train()\n",
    "        # Detaches it, brings it to CPU and back to Numpy\n",
    "        return y_hat_tensor.detach().cpu().numpy()\n",
    "\n",
    "    def plot_losses(self):\n",
    "        fig = plt.figure(figsize=(10, 4))\n",
    "        plt.plot(self.losses, label='Training Loss', c='b')\n",
    "        plt.plot(self.val_losses, label='Validation Loss', c='r')\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "\n",
    "    def add_graph(self):\n",
    "        # Fetches a single mini-batch so we can use add_graph\n",
    "        if self.train_loader and self.writer:\n",
    "            x_sample, y_sample = next(iter(self.train_loader))\n",
    "            self.writer.add_graph(self.model, x_sample.to(self.device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f8b40d688a12481f01eadf7380c47edd8a49484a47dba3db091451640e880c68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
